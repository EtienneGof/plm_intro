
Protein Language Models are Transformer-like models trained on massive sets of protein sequences (represented as text) to learn the biological 'grammar' of proteins. These models have a broad range of applications thanks to their generative and embedding abilities.

This repository is intended to be a pedagogical tool for users to discover this type of model, how they differ from their NLP counterparts, and the tasks they can address. we will also get a short overview of the existing open-source models and datasets.

After setting up a google Colab environment (Python), you will get familiar with protein language model by retrieving a protein language model from Huggingface's repository and start playing with a protein dataset from the literature. This includes exploring the dataset content, get to know more about the protein function prediction task and experiment simple encoding/decoding of proteins sequences.

<a target="_blank" href="https://colab.research.google.com/github/EtienneGof/plm_intro/blob/main/playin_with_protein.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a>

